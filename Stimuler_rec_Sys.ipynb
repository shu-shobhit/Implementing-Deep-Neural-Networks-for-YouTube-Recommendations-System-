{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Dy5NdM6F-SkF",
        "FSpTWuzY6bpy"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Synthetic Data Generation"
      ],
      "metadata": {
        "id": "X_-WKaoGCK4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ast import literal_eval\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re\n",
        "import ast"
      ],
      "metadata": {
        "id": "n4eVKNnMX-sS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# user_utterances_df = pd.read_csv('/content/user_utterances_df.csv')\n",
        "# user_profiles_df = pd.read_csv('/content/user_profiles_df.csv')\n",
        "# exercises_df = pd.read_csv('/content/exercises_df.csv')\n",
        "# user_interactions_df = pd.read_csv('/content/user_interactions_df.csv')"
      ],
      "metadata": {
        "id": "0yawwHy3UZ-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "user_utterances_dict = [{'interaction_id': 'user1_utterance1',\n",
        "  'user_id': 'user_1',\n",
        "  'timestamp': '2023-10-26T10:00:00Z',\n",
        "  'utterance': 'Hello, how are you?',\n",
        "  'grammar_score': 0.3745401188473625,\n",
        "  'grammar_errors': \"['Subject-verb agreement error']\",\n",
        "  'vocabulary_score': 0.6075448519014384,\n",
        "  'vocabulary_errors': \"['incorrect word usage']\",\n",
        "  'pronunciation_score': 0.388677289689482,\n",
        "  'pronunciation_errors': '[\"Mispronunciation of \\'th\\' sound\"]',\n",
        "  'fluency_score': 0.1195942459383017,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'},\n",
        " {'interaction_id': 'user1_utterance2',\n",
        "  'user_id': 'user_1',\n",
        "  'timestamp': '2023-10-26T10:05:00Z',\n",
        "  'utterance': 'I am from London, England.',\n",
        "  'grammar_score': 0.9507143064099162,\n",
        "  'grammar_errors': \"['Incorrect tense usage']\",\n",
        "  'vocabulary_score': 0.1705241236872915,\n",
        "  'vocabulary_errors': \"['wrong form of verb']\",\n",
        "  'pronunciation_score': 0.2713490317738959,\n",
        "  'pronunciation_errors': \"['Incorrect stress on syllables']\",\n",
        "  'fluency_score': 0.713244787222995,\n",
        "  'fluency_feedback': 'Excellent fluency and clear pronunciation.'},\n",
        " {'interaction_id': 'user1_utterance3',\n",
        "  'user_id': 'user_1',\n",
        "  'timestamp': '2023-10-26T10:10:00Z',\n",
        "  'utterance': 'I like to play football.',\n",
        "  'grammar_score': 0.7319939418114051,\n",
        "  'grammar_errors': \"['Run-on sentence']\",\n",
        "  'vocabulary_score': 0.0650515929852795,\n",
        "  'vocabulary_errors': \"['missing article']\",\n",
        "  'pronunciation_score': 0.8287375091519293,\n",
        "  'pronunciation_errors': \"['Vowel shortening in long vowel sounds']\",\n",
        "  'fluency_score': 0.7607850486168974,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'},\n",
        " {'interaction_id': 'user2_utterance1',\n",
        "  'user_id': 'user_2',\n",
        "  'timestamp': '2023-10-26T11:00:00Z',\n",
        "  'utterance': 'My name is John.',\n",
        "  'grammar_score': 0.5986584841970366,\n",
        "  'grammar_errors': \"['Misplaced modifier']\",\n",
        "  'vocabulary_score': 0.9488855372533332,\n",
        "  'vocabulary_errors': \"['conjunction']\",\n",
        "  'pronunciation_score': 0.3567533266935893,\n",
        "  'pronunciation_errors': '[\"Dropping the final \\'g\\' in words ending in \\'-ing\\'\"]',\n",
        "  'fluency_score': 0.5612771975694962,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'},\n",
        " {'interaction_id': 'user2_utterance2',\n",
        "  'user_id': 'user_2',\n",
        "  'timestamp': '2023-10-26T11:05:00Z',\n",
        "  'utterance': 'I am from New York.',\n",
        "  'grammar_score': 0.1560186404424365,\n",
        "  'grammar_errors': \"['Fragment', 'Missing subject']\",\n",
        "  'vocabulary_score': 0.9656320330745594,\n",
        "  'vocabulary_errors': \"['colloquialism used in formal context']\",\n",
        "  'pronunciation_score': 0.2809345096873807,\n",
        "  'pronunciation_errors': '[\"Confusion between \\'r\\' and \\'l\\' sounds\"]',\n",
        "  'fluency_score': 0.770967179954561,\n",
        "  'fluency_feedback': 'Excellent fluency and clear pronunciation.'},\n",
        " {'interaction_id': 'user2_utterance3',\n",
        "  'user_id': 'user_2',\n",
        "  'timestamp': '2023-10-26T11:10:00Z',\n",
        "  'utterance': 'I like to eat pizza.',\n",
        "  'grammar_score': 0.1559945203362026,\n",
        "  'grammar_errors': \"['Comma splice']\",\n",
        "  'vocabulary_score': 0.8083973481164611,\n",
        "  'vocabulary_errors': \"['slang term inappropriate for audience']\",\n",
        "  'pronunciation_score': 0.5426960831582485,\n",
        "  'pronunciation_errors': \"['Overemphasis of consonant clusters']\",\n",
        "  'fluency_score': 0.4937955963643907,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'},\n",
        " {'interaction_id': 'user3_utterance1',\n",
        "  'user_id': 'user_3',\n",
        "  'timestamp': '2023-10-26T12:00:00Z',\n",
        "  'utterance': 'What is your name?',\n",
        "  'grammar_score': 0.0580836121681994,\n",
        "  'grammar_errors': \"['Incorrect article usage']\",\n",
        "  'vocabulary_score': 0.3046137691733707,\n",
        "  'vocabulary_errors': \"['repetitive phrasing']\",\n",
        "  'pronunciation_score': 0.1409242249747626,\n",
        "  'pronunciation_errors': \"['Mispronunciation of diphthongs']\",\n",
        "  'fluency_score': 0.5227328293819941,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'},\n",
        " {'interaction_id': 'user3_utterance2',\n",
        "  'user_id': 'user_3',\n",
        "  'timestamp': '2023-10-26T12:05:00Z',\n",
        "  'utterance': 'I am from Paris, France.',\n",
        "  'grammar_score': 0.8661761457749352,\n",
        "  'grammar_errors': \"['Pronoun-antecedent agreement error', 'Subject-verb agreement error']\",\n",
        "  'vocabulary_score': 0.0976721140063838,\n",
        "  'vocabulary_errors': \"['word choice not precise']\",\n",
        "  'pronunciation_score': 0.8021969807540397,\n",
        "  'pronunciation_errors': '[\"Substitution of \\'w\\' for \\'r\\' sound\"]',\n",
        "  'fluency_score': 0.4275410183585496,\n",
        "  'fluency_feedback': 'Excellent fluency and clear pronunciation.'},\n",
        " {'interaction_id': 'user3_utterance3',\n",
        "  'user_id': 'user_3',\n",
        "  'timestamp': '2023-10-26T12:10:00Z',\n",
        "  'utterance': 'I like to eat croissants.',\n",
        "  'grammar_score': 0.6011150117432088,\n",
        "  'grammar_errors': \"['Double negative']\",\n",
        "  'vocabulary_score': 0.6842330265121569,\n",
        "  'vocabulary_errors': \"['overly complex vocabulary']\",\n",
        "  'pronunciation_score': 0.0745506436797708,\n",
        "  'pronunciation_errors': \"['Mispronunciation of silent letters']\",\n",
        "  'fluency_score': 0.0254191267440951,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'},\n",
        " {'interaction_id': 'user4_utterance1',\n",
        "  'user_id': 'user_4',\n",
        "  'timestamp': '2023-10-26T13:00:00Z',\n",
        "  'utterance': 'Nice to meet you.',\n",
        "  'grammar_score': 0.7080725777960455,\n",
        "  'grammar_errors': \"['Sentence fragment']\",\n",
        "  'vocabulary_score': 0.4401524937396013,\n",
        "  'vocabulary_errors': \"['missing article']\",\n",
        "  'pronunciation_score': 0.9868869366005172,\n",
        "  'pronunciation_errors': \"['Incorrect intonation in questions']\",\n",
        "  'fluency_score': 0.1078914269933044,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'},\n",
        " {'interaction_id': 'user4_utterance2',\n",
        "  'user_id': 'user_4',\n",
        "  'timestamp': '2023-10-26T13:05:00Z',\n",
        "  'utterance': 'I am from Tokyo, Japan.',\n",
        "  'grammar_score': 0.0205844942958024,\n",
        "  'grammar_errors': \"['Wrong preposition']\",\n",
        "  'vocabulary_score': 0.1220382348447788,\n",
        "  'vocabulary_errors': \"['incorrect plural form']\",\n",
        "  'pronunciation_score': 0.7722447692966574,\n",
        "  'pronunciation_errors': \"['Mispronunciation of the schwa sound']\",\n",
        "  'fluency_score': 0.0314291856867342,\n",
        "  'fluency_feedback': 'Excellent fluency and clear pronunciation.'},\n",
        " {'interaction_id': 'user4_utterance3',\n",
        "  'user_id': 'user_4',\n",
        "  'timestamp': '2023-10-26T13:10:00Z',\n",
        "  'utterance': 'I like to eat sushi.',\n",
        "  'grammar_score': 0.9699098521619944,\n",
        "  'grammar_errors': \"['Improper subject', 'Incorrect verb form']\",\n",
        "  'vocabulary_score': 0.4951769101112702,\n",
        "  'vocabulary_errors': \"['vague language']\",\n",
        "  'pronunciation_score': 0.1987156815341724,\n",
        "  'pronunciation_errors': \"['Lack of aspiration in plosive sounds']\",\n",
        "  'fluency_score': 0.6364104112637804,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'},\n",
        " {'interaction_id': 'user5_utterance1',\n",
        "  'user_id': 'user_5',\n",
        "  'timestamp': '2023-10-26T14:00:00Z',\n",
        "  'utterance': 'How old are you?',\n",
        "  'grammar_score': 0.8324426408004217,\n",
        "  'grammar_errors': \"['Lack of parallel structure']\",\n",
        "  'vocabulary_score': 0.0343885211152183,\n",
        "  'vocabulary_errors': \"['inconsistent tense usage']\",\n",
        "  'pronunciation_score': 0.0055221171236023,\n",
        "  'pronunciation_errors': '[\"Pronouncing \\'v\\' as \\'b\\'\"]',\n",
        "  'fluency_score': 0.3143559810763267,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'},\n",
        " {'interaction_id': 'user5_utterance2',\n",
        "  'user_id': 'user_5',\n",
        "  'timestamp': '2023-10-26T14:05:00Z',\n",
        "  'utterance': 'I am from Sydney, Australia.',\n",
        "  'grammar_score': 0.2123391106782761,\n",
        "  'grammar_errors': \"['Incorrect conjunction usage']\",\n",
        "  'vocabulary_score': 0.909320402078782,\n",
        "  'vocabulary_errors': \"['missing preposition']\",\n",
        "  'pronunciation_score': 0.8154614284548342,\n",
        "  'pronunciation_errors': '[\"Mispronunciation of \\'s\\' and \\'sh\\' sounds\"]',\n",
        "  'fluency_score': 0.5085706911647028,\n",
        "  'fluency_feedback': 'Excellent fluency and clear pronunciation.'},\n",
        " {'interaction_id': 'user5_utterance3',\n",
        "  'user_id': 'user_5',\n",
        "  'timestamp': '2023-10-26T14:10:00Z',\n",
        "  'utterance': 'I like to go to the beach.',\n",
        "  'grammar_score': 0.1818249672071006,\n",
        "  'grammar_errors': \"['Misuse of gerund']\",\n",
        "  'vocabulary_score': 0.2587799816000169,\n",
        "  'vocabulary_errors': \"['regional dialect not understood']\",\n",
        "  'pronunciation_score': 0.7068573438476171,\n",
        "  'pronunciation_errors': \"['Omission of consonants at word endings']\",\n",
        "  'fluency_score': 0.907566473926093,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'},\n",
        " {'interaction_id': 'user6_utterance1',\n",
        "  'user_id': 'user_6',\n",
        "  'timestamp': '2023-10-26T15:00:00Z',\n",
        "  'utterance': 'What are you doing?',\n",
        "  'grammar_score': 0.1834045098534338,\n",
        "  'grammar_errors': \"['Faulty parallelism']\",\n",
        "  'vocabulary_score': 0.662522284353982,\n",
        "  'vocabulary_errors': \"['preposition']\",\n",
        "  'pronunciation_score': 0.7290071680409873,\n",
        "  'pronunciation_errors': \"['Excessive nasalization of vowels']\",\n",
        "  'fluency_score': 0.2492922291488749,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'},\n",
        " {'interaction_id': 'user6_utterance2',\n",
        "  'user_id': 'user_6',\n",
        "  'timestamp': '2023-10-26T15:05:00Z',\n",
        "  'utterance': 'I am from Berlin, Germany.',\n",
        "  'grammar_score': 0.3042422429595377,\n",
        "  'grammar_errors': \"['Misused relative pronoun']\",\n",
        "  'vocabulary_score': 0.3117110760894109,\n",
        "  'vocabulary_errors': \"['inappropriate jargon']\",\n",
        "  'pronunciation_score': 0.7712703466859457,\n",
        "  'pronunciation_errors': \"['Flattening of pitch in rising intonation']\",\n",
        "  'fluency_score': 0.4103829230356297,\n",
        "  'fluency_feedback': 'Excellent fluency and clear pronunciation.'},\n",
        " {'interaction_id': 'user6_utterance3',\n",
        "  'user_id': 'user_6',\n",
        "  'timestamp': '2023-10-26T15:10:00Z',\n",
        "  'utterance': 'I like to drink beer.',\n",
        "  'grammar_score': 0.5247564316322378,\n",
        "  'grammar_errors': \"['Comma omission']\",\n",
        "  'vocabulary_score': 0.5200680211778108,\n",
        "  'vocabulary_errors': \"['uncommon synonym']\",\n",
        "  'pronunciation_score': 0.0740446517340903,\n",
        "  'pronunciation_errors': \"['Mispronunciation of voiced and voiceless sounds']\",\n",
        "  'fluency_score': 0.7555511385430487,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'},\n",
        " {'interaction_id': 'user7_utterance1',\n",
        "  'user_id': 'user_7',\n",
        "  'timestamp': '2023-10-26T16:00:00Z',\n",
        "  'utterance': 'I am from Seoul, South Korea.',\n",
        "  'grammar_score': 0.4319450186421157,\n",
        "  'grammar_errors': \"['Unclear antecedent']\",\n",
        "  'vocabulary_score': 0.5467102793432796,\n",
        "  'vocabulary_errors': \"['literal translation error']\",\n",
        "  'pronunciation_score': 0.3584657285442726,\n",
        "  'pronunciation_errors': \"['Over-pronunciation of unstressed syllables']\",\n",
        "  'fluency_score': 0.2287981654916224,\n",
        "  'fluency_feedback': 'Excellent fluency and clear pronunciation.'},\n",
        " {'interaction_id': 'user7_utterance2',\n",
        "  'user_id': 'user_7',\n",
        "  'timestamp': '2023-10-26T16:05:00Z',\n",
        "  'utterance': 'I like to eat kimchi.',\n",
        "  'grammar_score': 0.2912291401980419,\n",
        "  'grammar_errors': \"['Dangling participle']\",\n",
        "  'vocabulary_score': 0.184854455525527,\n",
        "  'vocabulary_errors': \"['incorrect word usage']\",\n",
        "  'pronunciation_score': 0.1158690595251297,\n",
        "  'pronunciation_errors': \"['Omission of vowel sounds in unstressed syllables']\",\n",
        "  'fluency_score': 0.0769799098287929,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'},\n",
        " {'interaction_id': 'user7_utterance3',\n",
        "  'user_id': 'user_7',\n",
        "  'timestamp': '2023-10-26T16:10:00Z',\n",
        "  'utterance': 'I like to watch K-dramas.',\n",
        "  'grammar_score': 0.6118528947223795,\n",
        "  'grammar_errors': \"['Inconsistent tense', 'Subject-verb agreement error']\",\n",
        "  'vocabulary_score': 0.9695846277645586,\n",
        "  'vocabulary_errors': \"['incorrect idiom usage']\",\n",
        "  'pronunciation_score': 0.8631034258755935,\n",
        "  'pronunciation_errors': '[\"Substitution of \\'f\\' for \\'th\\' sound\"]',\n",
        "  'fluency_score': 0.289751452913768,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'},\n",
        " {'interaction_id': 'user8_utterance1',\n",
        "  'user_id': 'user_8',\n",
        "  'timestamp': '2023-10-26T17:00:00Z',\n",
        "  'utterance': 'What is your favorite color?',\n",
        "  'grammar_score': 0.1394938606520418,\n",
        "  'grammar_errors': \"['Wrong pronoun case']\",\n",
        "  'vocabulary_score': 0.7751328233611146,\n",
        "  'vocabulary_errors': \"['too many filler words']\",\n",
        "  'pronunciation_score': 0.6232981268275579,\n",
        "  'pronunciation_errors': '[\"Mispronunciation of \\'ch\\' as \\'sh\\'\"]',\n",
        "  'fluency_score': 0.1612212872540044,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'},\n",
        " {'interaction_id': 'user8_utterance2',\n",
        "  'user_id': 'user_8',\n",
        "  'timestamp': '2023-10-26T17:05:00Z',\n",
        "  'utterance': 'I am from Mumbai, India.',\n",
        "  'grammar_score': 0.2921446485352181,\n",
        "  'grammar_errors': \"['Redundant phrasing']\",\n",
        "  'vocabulary_score': 0.9394989415641892,\n",
        "  'vocabulary_errors': \"['inaccurate term for context']\",\n",
        "  'pronunciation_score': 0.3308980248526492,\n",
        "  'pronunciation_errors': \"['Shortening of diphthongs into monophthongs']\",\n",
        "  'fluency_score': 0.9296976523425732,\n",
        "  'fluency_feedback': 'Excellent fluency and clear pronunciation.'},\n",
        " {'interaction_id': 'user8_utterance3',\n",
        "  'user_id': 'user_8',\n",
        "  'timestamp': '2023-10-26T17:10:00Z',\n",
        "  'utterance': 'I like to eat curry.',\n",
        "  'grammar_score': 0.3663618432936917,\n",
        "  'grammar_errors': \"['Overly complex sentence']\",\n",
        "  'vocabulary_score': 0.8948273504276488,\n",
        "  'vocabulary_errors': \"['word order confusion']\",\n",
        "  'pronunciation_score': 0.0635583502860236,\n",
        "  'pronunciation_errors': \"['Inconsistent stress in multi-syllable words']\",\n",
        "  'fluency_score': 0.808120379564417,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'},\n",
        " {'interaction_id': 'user9_utterance1',\n",
        "  'user_id': 'user_9',\n",
        "  'timestamp': '2023-10-26T18:00:00Z',\n",
        "  'utterance': 'Do you like to travel?',\n",
        "  'grammar_score': 0.4560699842170359,\n",
        "  'grammar_errors': \"['Missing punctuation']\",\n",
        "  'vocabulary_score': 0.5978999788110851,\n",
        "  'vocabulary_errors': \"['ambiguous word choice']\",\n",
        "  'pronunciation_score': 0.3109823217156622,\n",
        "  'pronunciation_errors': '[\"Mispronunciation of \\'t\\' in flapped sounds\"]',\n",
        "  'fluency_score': 0.6334037565104235,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'},\n",
        " {'interaction_id': 'user9_utterance2',\n",
        "  'user_id': 'user_9',\n",
        "  'timestamp': '2023-10-26T18:05:00Z',\n",
        "  'utterance': 'I am from Cairo, Egypt.',\n",
        "  'grammar_score': 0.7851759613930136,\n",
        "  'grammar_errors': \"['Overuse of passive voice']\",\n",
        "  'vocabulary_score': 0.9218742350231168,\n",
        "  'vocabulary_errors': \"['missing conjunction']\",\n",
        "  'pronunciation_score': 0.325183322026747,\n",
        "  'pronunciation_errors': \"['Unclear pronunciation of glottal stops']\",\n",
        "  'fluency_score': 0.8714605901877177,\n",
        "  'fluency_feedback': 'Excellent fluency and clear pronunciation.'},\n",
        " {'interaction_id': 'user9_utterance3',\n",
        "  'user_id': 'user_9',\n",
        "  'timestamp': '2023-10-26T18:10:00Z',\n",
        "  'utterance': 'I like to eat falafel.',\n",
        "  'grammar_score': 0.1996737821583597,\n",
        "  'grammar_errors': \"['Improper ellipsis usage']\",\n",
        "  'vocabulary_score': 0.0884925020519195,\n",
        "  'vocabulary_errors': \"['outdated terminology']\",\n",
        "  'pronunciation_score': 0.7296061783380641,\n",
        "  'pronunciation_errors': \"['Reduction of vowel sounds in connected speech']\",\n",
        "  'fluency_score': 0.8036720768991145,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'},\n",
        " {'interaction_id': 'user10_utterance1',\n",
        "  'user_id': 'user_10',\n",
        "  'timestamp': '2023-10-26T19:00:00Z',\n",
        "  'utterance': 'What is your favorite animal?',\n",
        "  'grammar_score': 0.5142344384136116,\n",
        "  'grammar_errors': \"['Incorrect possessive form']\",\n",
        "  'vocabulary_score': 0.1959828624191452,\n",
        "  'vocabulary_errors': \"['excessive jargon']\",\n",
        "  'pronunciation_score': 0.6375574713552131,\n",
        "  'pronunciation_errors': '[\"Dropping the \\'h\\' sound at the beginning of words\"]',\n",
        "  'fluency_score': 0.1865700588860358,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'},\n",
        " {'interaction_id': 'user10_utterance2',\n",
        "  'user_id': 'user_10',\n",
        "  'timestamp': '2023-10-26T19:05:00Z',\n",
        "  'utterance': 'I am from Moscow, Russia.',\n",
        "  'grammar_score': 0.5924145688620425,\n",
        "  'grammar_errors': \"['Inappropriate word choice']\",\n",
        "  'vocabulary_score': 0.045227288910538,\n",
        "  'vocabulary_errors': \"['inconsistent vocabulary level']\",\n",
        "  'pronunciation_score': 0.8872127425763265,\n",
        "  'pronunciation_errors': '[\"Pronouncing \\'z\\' as \\'s\\'\"]',\n",
        "  'fluency_score': 0.8925589984899778,\n",
        "  'fluency_feedback': 'Excellent fluency and clear pronunciation.'},\n",
        " {'interaction_id': 'user10_utterance3',\n",
        "  'user_id': 'user_10',\n",
        "  'timestamp': '2023-10-26T19:10:00Z',\n",
        "  'utterance': 'I like to eat borscht.',\n",
        "  'grammar_score': 0.0464504127199977,\n",
        "  'grammar_errors': \"['Dangling modifier', 'Sentence fragment']\",\n",
        "  'vocabulary_score': 0.3253303307632643,\n",
        "  'vocabulary_errors': \"['wrong adjective form']\",\n",
        "  'pronunciation_score': 0.4722149251619493,\n",
        "  'pronunciation_errors': \"['Incorrect use of rising intonation for statements']\",\n",
        "  'fluency_score': 0.5393422419156507,\n",
        "  'fluency_feedback': 'Good fluency and natural rhythm.'}]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MkJ5O3VNYU0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "user_interactions_dict = [{'interaction_id': 'interaction_1',\n",
        "  'user_id': 'user_1',\n",
        "  'exercise_id': 'exercise_1',\n",
        "  'timestamp': '2023-10-26T10:00:00Z',\n",
        "  'performance': 0.8074401551640625,\n",
        "  'time_spent': 120,\n",
        "  'user_response': 'I went to the store yesterday.',\n",
        "  'user_feedback': \"Good job! You correctly used the past tense of 'go'.\"},\n",
        " {'interaction_id': 'interaction_2',\n",
        "  'user_id': 'user_2',\n",
        "  'exercise_id': 'exercise_2',\n",
        "  'timestamp': '2023-10-26T10:15:00Z',\n",
        "  'performance': 0.8960912999234932,\n",
        "  'time_spent': 90,\n",
        "  'user_response': 'The meal was delicious, I had two helpings.',\n",
        "  'user_feedback': 'Excellent! You used the correct vocabulary word.'},\n",
        " {'interaction_id': 'interaction_3',\n",
        "  'user_id': 'user_3',\n",
        "  'exercise_id': 'exercise_3',\n",
        "  'timestamp': '2023-10-26T10:30:00Z',\n",
        "  'performance': 0.3180034749718639,\n",
        "  'time_spent': 150,\n",
        "  'user_response': 'The cat sat on the mat.',\n",
        "  'user_feedback': \"Not bad! You pronounced some words correctly, but work on the 'th' sound.\"},\n",
        " {'interaction_id': 'interaction_4',\n",
        "  'user_id': 'user_4',\n",
        "  'exercise_id': 'exercise_4',\n",
        "  'timestamp': '2023-10-26T10:45:00Z',\n",
        "  'performance': 0.1100519245276767,\n",
        "  'time_spent': 180,\n",
        "  'user_response': 'I am going to the stores.',\n",
        "  'user_feedback': \"Close! Remember to use the singular form of 'store' when referring to a general store.\"},\n",
        " {'interaction_id': 'interaction_5',\n",
        "  'user_id': 'user_5',\n",
        "  'exercise_id': 'exercise_5',\n",
        "  'timestamp': '2023-10-26T11:00:00Z',\n",
        "  'performance': 0.2279351625419416,\n",
        "  'time_spent': 105,\n",
        "  'user_response': 'I like to listen to classical music.',\n",
        "  'user_feedback': 'Good! You used the correct vocabulary word.'},\n",
        " {'interaction_id': 'interaction_6',\n",
        "  'user_id': 'user_6',\n",
        "  'exercise_id': 'exercise_6',\n",
        "  'timestamp': '2023-10-26T11:15:00Z',\n",
        "  'performance': 0.4271077886262563,\n",
        "  'time_spent': 120,\n",
        "  'user_response': 'She likes to go to the beach.',\n",
        "  'user_feedback': \"Great! You pronounced most words correctly, just watch the 'ea' sound in 'beach'.\"},\n",
        " {'interaction_id': 'interaction_7',\n",
        "  'user_id': 'user_7',\n",
        "  'exercise_id': 'exercise_7',\n",
        "  'timestamp': '2023-10-26T11:30:00Z',\n",
        "  'performance': 0.8180147659224931,\n",
        "  'time_spent': 165,\n",
        "  'user_response': 'He is sitting on the table.',\n",
        "  'user_feedback': \"Good try! You chose the correct preposition, but remember to use 'at' when referring to a specific location.\"},\n",
        " {'interaction_id': 'interaction_8',\n",
        "  'user_id': 'user_8',\n",
        "  'exercise_id': 'exercise_8',\n",
        "  'timestamp': '2023-10-26T11:45:00Z',\n",
        "  'performance': 0.8607305832563434,\n",
        "  'time_spent': 110,\n",
        "  'user_response': 'The sun is very bright today.',\n",
        "  'user_feedback': 'Excellent! You used the correct vocabulary word.'},\n",
        " {'interaction_id': 'interaction_9',\n",
        "  'user_id': 'user_9',\n",
        "  'exercise_id': 'exercise_9',\n",
        "  'timestamp': '2023-10-26T12:00:00Z',\n",
        "  'performance': 0.0069521305311907,\n",
        "  'time_spent': 135,\n",
        "  'user_response': 'I want to go to the park.',\n",
        "  'user_feedback': \"Not quite! Work on the 'w' sound and the 'r' sound at the end of 'park'.\"},\n",
        " {'interaction_id': 'interaction_10',\n",
        "  'user_id': 'user_10',\n",
        "  'exercise_id': 'exercise_10',\n",
        "  'timestamp': '2023-10-26T12:15:00Z',\n",
        "  'performance': 0.5107473025775657,\n",
        "  'time_spent': 100,\n",
        "  'user_response': 'We are going to the movies.',\n",
        "  'user_feedback': 'Perfect! You chose the correct pronoun.'},\n",
        " {'interaction_id': 'interaction_11',\n",
        "  'user_id': 'user_1',\n",
        "  'exercise_id': 'exercise_2',\n",
        "  'timestamp': '2023-10-27T10:00:00Z',\n",
        "  'performance': 0.417411003148779,\n",
        "  'time_spent': 100,\n",
        "  'user_response': 'The meal was yummy, I had two helpings.',\n",
        "  'user_feedback': \"Good attempt! Remember that 'delicious' is a more formal and accurate word to describe food.\"},\n",
        " {'interaction_id': 'interaction_12',\n",
        "  'user_id': 'user_2',\n",
        "  'exercise_id': 'exercise_3',\n",
        "  'timestamp': '2023-10-27T10:15:00Z',\n",
        "  'performance': 0.2221078104707302,\n",
        "  'time_spent': 120,\n",
        "  'user_response': 'The cat sat on the mat.',\n",
        "  'user_feedback': \"Great! You pronounced most words correctly, just work on the 's' sound in 'sat'.\"},\n",
        " {'interaction_id': 'interaction_13',\n",
        "  'user_id': 'user_3',\n",
        "  'exercise_id': 'exercise_4',\n",
        "  'timestamp': '2023-10-27T10:30:00Z',\n",
        "  'performance': 0.1198653673336828,\n",
        "  'time_spent': 150,\n",
        "  'user_response': 'I am going to the store.',\n",
        "  'user_feedback': \"Try again! The plural form of 'store' is needed in this sentence.\"},\n",
        " {'interaction_id': 'interaction_14',\n",
        "  'user_id': 'user_4',\n",
        "  'exercise_id': 'exercise_5',\n",
        "  'timestamp': '2023-10-27T10:45:00Z',\n",
        "  'performance': 0.3376151714036279,\n",
        "  'time_spent': 180,\n",
        "  'user_response': 'I like to listen to rock and roll music.',\n",
        "  'user_feedback': \"Close! While 'rock and roll' is a type of music, the question is asking for a more general genre.\"},\n",
        " {'interaction_id': 'interaction_15',\n",
        "  'user_id': 'user_5',\n",
        "  'exercise_id': 'exercise_6',\n",
        "  'timestamp': '2023-10-27T11:00:00Z',\n",
        "  'performance': 0.9429097039125192,\n",
        "  'time_spent': 105,\n",
        "  'user_response': 'She likes to go to the beach.',\n",
        "  'user_feedback': \"Good attempt! You pronounced most words correctly, but work on the 'sh' sound in 'she'.\"},\n",
        " {'interaction_id': 'interaction_16',\n",
        "  'user_id': 'user_6',\n",
        "  'exercise_id': 'exercise_7',\n",
        "  'timestamp': '2023-10-27T11:15:00Z',\n",
        "  'performance': 0.3232029320207552,\n",
        "  'time_spent': 120,\n",
        "  'user_response': 'He is sitting on the table.',\n",
        "  'user_feedback': \"Great! You chose the correct preposition, but remember to use 'at' when referring to a specific location.\"},\n",
        " {'interaction_id': 'interaction_17',\n",
        "  'user_id': 'user_7',\n",
        "  'exercise_id': 'exercise_8',\n",
        "  'timestamp': '2023-10-27T11:30:00Z',\n",
        "  'performance': 0.5187906217433661,\n",
        "  'time_spent': 165,\n",
        "  'user_response': 'The weather is very bright today.',\n",
        "  'user_feedback': 'Excellent! You used the correct vocabulary word.'},\n",
        " {'interaction_id': 'interaction_18',\n",
        "  'user_id': 'user_8',\n",
        "  'exercise_id': 'exercise_9',\n",
        "  'timestamp': '2023-10-27T11:45:00Z',\n",
        "  'performance': 0.7030189588951778,\n",
        "  'time_spent': 110,\n",
        "  'user_response': 'I want to go to the park.',\n",
        "  'user_feedback': \"Try again!  Pay attention to the 't' sound in 'want' and the 'r' sound at the end of 'park'.\"},\n",
        " {'interaction_id': 'interaction_19',\n",
        "  'user_id': 'user_9',\n",
        "  'exercise_id': 'exercise_10',\n",
        "  'timestamp': '2023-10-27T12:00:00Z',\n",
        "  'performance': 0.363629602379294,\n",
        "  'time_spent': 135,\n",
        "  'user_response': 'You are going to the movies.',\n",
        "  'user_feedback': \"Good try! Remember the subject of the sentence is 'we', so the pronoun should reflect that.\"},\n",
        " {'interaction_id': 'interaction_20',\n",
        "  'user_id': 'user_10',\n",
        "  'exercise_id': 'exercise_1',\n",
        "  'timestamp': '2023-10-27T12:15:00Z',\n",
        "  'performance': 0.9717820827209608,\n",
        "  'time_spent': 100,\n",
        "  'user_response': 'I go to the store yesterday.',\n",
        "  'user_feedback': \"Good job! You correctly used the past tense of 'go'.\"},\n",
        " {'interaction_id': 'interaction_21',\n",
        "  'user_id': 'user_1',\n",
        "  'exercise_id': 'exercise_3',\n",
        "  'timestamp': '2023-10-28T10:00:00Z',\n",
        "  'performance': 0.9624472949421112,\n",
        "  'time_spent': 120,\n",
        "  'user_response': 'The cat sat on the mat.',\n",
        "  'user_feedback': \"Great! You pronounced most words correctly, just work on the 's' sound in 'sat'.\"},\n",
        " {'interaction_id': 'interaction_22',\n",
        "  'user_id': 'user_2',\n",
        "  'exercise_id': 'exercise_4',\n",
        "  'timestamp': '2023-10-28T10:15:00Z',\n",
        "  'performance': 0.2517822958253641,\n",
        "  'time_spent': 90,\n",
        "  'user_response': 'I am going to the stores.',\n",
        "  'user_feedback': \"Close! Remember to use the singular form of 'store' when referring to a general store.\"},\n",
        " {'interaction_id': 'interaction_23',\n",
        "  'user_id': 'user_3',\n",
        "  'exercise_id': 'exercise_5',\n",
        "  'timestamp': '2023-10-28T10:30:00Z',\n",
        "  'performance': 0.4972485058923854,\n",
        "  'time_spent': 150,\n",
        "  'user_response': 'I like to listen to classical music.',\n",
        "  'user_feedback': 'Good! You used the correct vocabulary word.'},\n",
        " {'interaction_id': 'interaction_24',\n",
        "  'user_id': 'user_4',\n",
        "  'exercise_id': 'exercise_6',\n",
        "  'timestamp': '2023-10-28T10:45:00Z',\n",
        "  'performance': 0.3008783098167696,\n",
        "  'time_spent': 180,\n",
        "  'user_response': 'She likes to go to the beach.',\n",
        "  'user_feedback': \"Great! You pronounced most words correctly, just watch the 'ea' sound in 'beach'.\"},\n",
        " {'interaction_id': 'interaction_25',\n",
        "  'user_id': 'user_5',\n",
        "  'exercise_id': 'exercise_7',\n",
        "  'timestamp': '2023-10-28T11:00:00Z',\n",
        "  'performance': 0.2848404943774676,\n",
        "  'time_spent': 105,\n",
        "  'user_response': 'He is sitting at the table.',\n",
        "  'user_feedback': 'Excellent! You chose the correct preposition.'},\n",
        " {'interaction_id': 'interaction_26',\n",
        "  'user_id': 'user_6',\n",
        "  'exercise_id': 'exercise_8',\n",
        "  'timestamp': '2023-10-28T11:15:00Z',\n",
        "  'performance': 0.0368869473545327,\n",
        "  'time_spent': 120,\n",
        "  'user_response': 'The sun is very bright today.',\n",
        "  'user_feedback': 'Good attempt! You understood the concept but try using a different word to describe the weather.'},\n",
        " {'interaction_id': 'interaction_27',\n",
        "  'user_id': 'user_7',\n",
        "  'exercise_id': 'exercise_9',\n",
        "  'timestamp': '2023-10-28T11:30:00Z',\n",
        "  'performance': 0.6095643339798968,\n",
        "  'time_spent': 165,\n",
        "  'user_response': 'I want to go to the park.',\n",
        "  'user_feedback': \"Great! You pronounced most words correctly, just work on the 'w' sound in 'want'.\"},\n",
        " {'interaction_id': 'interaction_28',\n",
        "  'user_id': 'user_8',\n",
        "  'exercise_id': 'exercise_10',\n",
        "  'timestamp': '2023-10-28T11:45:00Z',\n",
        "  'performance': 0.5026790232288615,\n",
        "  'time_spent': 110,\n",
        "  'user_response': 'You are going to the movies.',\n",
        "  'user_feedback': \"Try again! Remember the subject of the sentence is 'we', so the pronoun should reflect that.\"},\n",
        " {'interaction_id': 'interaction_29',\n",
        "  'user_id': 'user_9',\n",
        "  'exercise_id': 'exercise_1',\n",
        "  'timestamp': '2023-10-28T12:00:00Z',\n",
        "  'performance': 0.0514787512499893,\n",
        "  'time_spent': 135,\n",
        "  'user_response': 'I went to the store yesterday.',\n",
        "  'user_feedback': \"Perfect! You correctly used the past tense of 'go'.\"},\n",
        " {'interaction_id': 'interaction_30',\n",
        "  'user_id': 'user_10',\n",
        "  'exercise_id': 'exercise_2',\n",
        "  'timestamp': '2023-10-28T12:15:00Z',\n",
        "  'performance': 0.2786464642366114,\n",
        "  'time_spent': 100,\n",
        "  'user_response': 'The meal was yummy, I had two helpings.',\n",
        "  'user_feedback': \"Good attempt! Remember that 'delicious' is a more formal and accurate word to describe food.\"}]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CgWx40zkYr6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "user_profiles_dict = [{'user_id': 'user_1',\n",
        "  'age': 25,\n",
        "  'location': 'New York, USA',\n",
        "  'native_language': 'Spanish',\n",
        "  'proficiency_level': 'Intermediate',\n",
        "  'interests': \"['Travel', 'History', 'Music', 'Technology']\",\n",
        "  'preferred_learning_style': 'Visual'},\n",
        " {'user_id': 'user_2',\n",
        "  'age': 32,\n",
        "  'location': 'London, UK',\n",
        "  'native_language': 'French',\n",
        "  'proficiency_level': 'Advanced',\n",
        "  'interests': \"['Science', 'Movies', 'Cooking', 'Art']\",\n",
        "  'preferred_learning_style': 'Auditory'},\n",
        " {'user_id': 'user_3',\n",
        "  'age': 19,\n",
        "  'location': 'Tokyo, Japan',\n",
        "  'native_language': 'Japanese',\n",
        "  'proficiency_level': 'Beginner',\n",
        "  'interests': \"['Sports', 'Games', 'Fashion', 'Literature']\",\n",
        "  'preferred_learning_style': 'Kinesthetic'},\n",
        " {'user_id': 'user_4',\n",
        "  'age': 48,\n",
        "  'location': 'Sydney, Australia',\n",
        "  'native_language': 'Mandarin',\n",
        "  'proficiency_level': 'Advanced',\n",
        "  'interests': \"['Nature', 'Photography', 'Business', 'Music']\",\n",
        "  'preferred_learning_style': 'Visual'},\n",
        " {'user_id': 'user_5',\n",
        "  'age': 28,\n",
        "  'location': 'Berlin, Germany',\n",
        "  'native_language': 'German',\n",
        "  'proficiency_level': 'Intermediate',\n",
        "  'interests': \"['Technology', 'Politics', 'Travel', 'Food']\",\n",
        "  'preferred_learning_style': 'Auditory'},\n",
        " {'user_id': 'user_6',\n",
        "  'age': 35,\n",
        "  'location': 'Paris, France',\n",
        "  'native_language': 'French',\n",
        "  'proficiency_level': 'Advanced',\n",
        "  'interests': \"['Art', 'History', 'Literature', 'Music']\",\n",
        "  'preferred_learning_style': 'Visual'},\n",
        " {'user_id': 'user_7',\n",
        "  'age': 22,\n",
        "  'location': 'Seoul, South Korea',\n",
        "  'native_language': 'Korean',\n",
        "  'proficiency_level': 'Beginner',\n",
        "  'interests': \"['Movies', 'Music', 'Gaming', 'Technology']\",\n",
        "  'preferred_learning_style': 'Auditory'},\n",
        " {'user_id': 'user_8',\n",
        "  'age': 41,\n",
        "  'location': 'Toronto, Canada',\n",
        "  'native_language': 'French',\n",
        "  'proficiency_level': 'Intermediate',\n",
        "  'interests': \"['Travel', 'Food', 'Sports', 'Nature']\",\n",
        "  'preferred_learning_style': 'Kinesthetic'},\n",
        " {'user_id': 'user_9',\n",
        "  'age': 29,\n",
        "  'location': 'Rome, Italy',\n",
        "  'native_language': 'Italian',\n",
        "  'proficiency_level': 'Advanced',\n",
        "  'interests': \"['Art', 'History', 'Food', 'Music']\",\n",
        "  'preferred_learning_style': 'Visual'},\n",
        " {'user_id': 'user_10',\n",
        "  'age': 38,\n",
        "  'location': 'Madrid, Spain',\n",
        "  'native_language': 'Spanish',\n",
        "  'proficiency_level': 'Intermediate',\n",
        "  'interests': \"['Technology', 'Business', 'Travel', 'Sports']\",\n",
        "  'preferred_learning_style': 'Auditory'}]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GVAuAgO1ZMRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "exercises_dict = [{'exercise_id': 'exercise_1',\n",
        "  'type': 'Multiple Choice',\n",
        "  'category': 'Grammar',\n",
        "  'difficulty': 0.5,\n",
        "  'content': 'Choose the correct verb tense:  I ____ to the store yesterday.',\n",
        "  'metadata': \"{'topic': 'Past Tense', 'cultural_context': 'None', 'target_error_types': ['Verb Tense']}\"},\n",
        " {'exercise_id': 'exercise_2',\n",
        "  'type': 'Fill-in-the-Blank',\n",
        "  'category': 'Vocabulary',\n",
        "  'difficulty': 0.7,\n",
        "  'content': 'The ____ was delicious, I had two helpings.',\n",
        "  'metadata': \"{'topic': 'Food', 'cultural_context': 'None', 'target_error_types': ['Vocabulary']}\"},\n",
        " {'exercise_id': 'exercise_3',\n",
        "  'type': 'Speaking',\n",
        "  'category': 'Pronunciation',\n",
        "  'difficulty': 0.3,\n",
        "  'content': 'Record yourself saying the sentence: \"The cat sat on the mat.\"',\n",
        "  'metadata': \"{'topic': 'Basic Sounds', 'cultural_context': 'None', 'target_error_types': ['Pronunciation']}\"},\n",
        " {'exercise_id': 'exercise_4',\n",
        "  'type': 'Multiple Choice',\n",
        "  'category': 'Grammar',\n",
        "  'difficulty': 0.8,\n",
        "  'content': 'Which sentence is grammatically correct:  a) I am going to the store.  b) I am going to the stores.',\n",
        "  'metadata': \"{'topic': 'Articles', 'cultural_context': 'None', 'target_error_types': ['Articles']}\"},\n",
        " {'exercise_id': 'exercise_5',\n",
        "  'type': 'Fill-in-the-Blank',\n",
        "  'category': 'Vocabulary',\n",
        "  'difficulty': 0.6,\n",
        "  'content': 'I like to listen to ____ music.',\n",
        "  'metadata': \"{'topic': 'Music Genres', 'cultural_context': 'None', 'target_error_types': ['Vocabulary']}\"},\n",
        " {'exercise_id': 'exercise_6',\n",
        "  'type': 'Speaking',\n",
        "  'category': 'Pronunciation',\n",
        "  'difficulty': 0.4,\n",
        "  'content': 'Record yourself saying the sentence: \"She likes to go to the beach.\"',\n",
        "  'metadata': \"{'topic': 'Vowel Sounds', 'cultural_context': 'None', 'target_error_types': ['Pronunciation']}\"},\n",
        " {'exercise_id': 'exercise_7',\n",
        "  'type': 'Multiple Choice',\n",
        "  'category': 'Grammar',\n",
        "  'difficulty': 0.9,\n",
        "  'content': 'Choose the correct preposition:  He is sitting ____ the table.',\n",
        "  'metadata': \"{'topic': 'Prepositions', 'cultural_context': 'None', 'target_error_types': ['Prepositions']}\"},\n",
        " {'exercise_id': 'exercise_8',\n",
        "  'type': 'Fill-in-the-Blank',\n",
        "  'category': 'Vocabulary',\n",
        "  'difficulty': 0.5,\n",
        "  'content': 'The ____ is very bright today.',\n",
        "  'metadata': \"{'topic': 'Weather', 'cultural_context': 'None', 'target_error_types': ['Vocabulary']}\"},\n",
        " {'exercise_id': 'exercise_9',\n",
        "  'type': 'Speaking',\n",
        "  'category': 'Pronunciation',\n",
        "  'difficulty': 0.2,\n",
        "  'content': 'Record yourself saying the sentence: \"I want to go to the park.\"',\n",
        "  'metadata': \"{'topic': 'Consonant Sounds', 'cultural_context': 'None', 'target_error_types': ['Pronunciation']}\"},\n",
        " {'exercise_id': 'exercise_10',\n",
        "  'type': 'Multiple Choice',\n",
        "  'category': 'Grammar',\n",
        "  'difficulty': 0.7,\n",
        "  'content': 'Choose the correct pronoun:  ____ are going to the movies.',\n",
        "  'metadata': \"{'topic': 'Pronouns', 'cultural_context': 'None', 'target_error_types': ['Pronouns']}\"}]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qWqwgy0dZYeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exercises_df = pd.DataFrame(exercises_dict)\n",
        "user_interactions_df = pd.DataFrame(user_interactions_dict)\n",
        "user_utterances_df = pd.DataFrame(user_utterances_dict)\n",
        "user_profiles_df = pd.DataFrame(user_profiles_dict)"
      ],
      "metadata": {
        "id": "3JNvNBnzYRFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Candidate Generation pre-training\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rwHdeeAC9r7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1**. More complexity would be there in the pre-training Candidate Generation when training on Real data, as at different timestamps we could create different instances of data for each user. We could incorporate that using timestamp information at different steps. here i am creating only one instance of data per user for simplicity. We can also have variable timestamps.\n",
        "\n",
        "**2**.  have simply padded features to a constant length. But we could incorporate constant padding for features which are to be fed directly to FC layers and batch_level+feature_level_max_length padding for features which are to be fed to LSTM layers.\n",
        "\n",
        "**3.** We could incorporate good pre-trained word-level embeddings (Glove, word2vec) or Pre trained LM encodings too, for much better performance. But here I am making a custom vocabulary and then embedding.\n"
      ],
      "metadata": {
        "id": "GKkj5f3LGd5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vocabulary(user_profiles_df, user_interactions_df, user_utterances_df, exercises_df):\n",
        "    vocab = Counter()\n",
        "\n",
        "    # Helper function to tokenize text\n",
        "    def tokenize(text):\n",
        "        return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "    # Process user_utterances_df\n",
        "    vocab.update(tokenize(' '.join(user_utterances_df['utterance'])))\n",
        "    vocab.update(tokenize(' '.join(user_utterances_df['grammar_errors'].apply(lambda x: ' '.join(ast.literal_eval(x))))))\n",
        "    vocab.update(tokenize(' '.join(user_utterances_df['vocabulary_errors'].apply(lambda x: ' '.join(ast.literal_eval(x))))))\n",
        "    vocab.update(tokenize(' '.join(user_utterances_df['pronunciation_errors'].apply(lambda x: ' '.join(ast.literal_eval(x))))))\n",
        "    vocab.update(tokenize(' '.join(user_utterances_df['fluency_feedback'])))\n",
        "\n",
        "    # Process user_profiles_df\n",
        "    vocab.update(tokenize(' '.join(user_profiles_df['location'])))\n",
        "    vocab.update(tokenize(' '.join(user_profiles_df['native_language'])))\n",
        "    vocab.update(tokenize(' '.join(user_profiles_df['proficiency_level'])))\n",
        "    vocab.update(tokenize(' '.join(user_profiles_df['interests'].apply(lambda x: ' '.join(ast.literal_eval(x))))))\n",
        "    vocab.update(tokenize(' '.join(user_profiles_df['preferred_learning_style'])))\n",
        "\n",
        "    # Process user_interactions_df\n",
        "    vocab.update(tokenize(' '.join(user_interactions_df['user_response'])))\n",
        "    vocab.update(tokenize(' '.join(user_interactions_df['user_feedback'])))\n",
        "\n",
        "    # Process exercises_df\n",
        "    vocab.update(tokenize(' '.join(exercises_df['type'])))\n",
        "    vocab.update(tokenize(' '.join(exercises_df['category'])))\n",
        "    vocab.update(tokenize(' '.join(exercises_df['content'])))\n",
        "    vocab.update(tokenize(' '.join(exercises_df['metadata'].apply(lambda x: str(ast.literal_eval(x))))))\n",
        "\n",
        "    # Create vocabulary dictionary\n",
        "    vocab_dict = {'<PAD>': 0, '<UNK>': 1}  # Add padding and unknown tokens\n",
        "    for idx, (word, _) in enumerate(vocab.most_common(), start=2):\n",
        "        vocab_dict[word] = idx\n",
        "\n",
        "    return vocab_dict\n",
        "\n",
        "\n",
        "vocab = create_vocabulary(user_profiles_df, user_interactions_df, user_utterances_df, exercises_df)\n",
        "vocab_size = len(vocab)\n",
        "print(f\"Vocabulary size: {vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaqWDlRf3JjB",
        "outputId": "0abd0a99-db68-4bc8-87bb-b6d3e5bf43c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "-- -- -- -- -- -- -- -- -- -- --"
      ],
      "metadata": {
        "id": "Eg1TnEl_U-OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class CandidateGenerationDataset(Dataset):\n",
        "    def __init__(self, user_profiles_df, user_interactions_df, user_utterances_df, exercises_df, vocab, seq_length=5):\n",
        "        self.user_profiles = user_profiles_df\n",
        "        self.user_interactions = user_interactions_df\n",
        "        self.user_utterances = user_utterances_df\n",
        "        self.exercises = exercises_df\n",
        "        self.seq_length = seq_length\n",
        "        self.vocab = vocab\n",
        "        self.user_sequences = self._prepare_user_sequences()\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.user_profiles)\n",
        "\n",
        "    def _prepare_user_sequences(self):\n",
        "        user_sequences = {}\n",
        "        for user_id in self.user_profiles['user_id'].unique():\n",
        "            user_interactions = self.user_interactions[self.user_interactions['user_id'] == user_id].sort_values('timestamp')\n",
        "            user_utterances = self.user_utterances[self.user_utterances['user_id'] == user_id].sort_values('timestamp')\n",
        "\n",
        "            interaction_seq = user_interactions[['exercise_id', 'performance', 'time_spent', 'user_response', 'user_feedback']].to_dict('records')\n",
        "            utterance_seq = user_utterances[['utterance', 'grammar_score', 'grammar_errors', 'vocabulary_score',\n",
        "                                             'vocabulary_errors', 'pronunciation_score', 'pronunciation_errors',\n",
        "                                             'fluency_score', 'fluency_feedback']].to_dict('records')\n",
        "\n",
        "            # Convert text to tensor indices\n",
        "            for interaction in interaction_seq:\n",
        "                interaction['user_response'] = torch.tensor(self._text_to_indices(interaction['user_response']))\n",
        "                interaction['user_feedback'] = torch.tensor(self._text_to_indices(interaction['user_feedback']))\n",
        "                interaction['performance'] = torch.tensor(interaction['performance'])\n",
        "                interaction['time_spent'] = torch.tensor(interaction['time_spent'])\n",
        "\n",
        "            for utterance in utterance_seq:\n",
        "                utterance['utterance'] = torch.tensor(self._text_to_indices(utterance['utterance']))\n",
        "                utterance['grammar_errors'] = torch.cat([t for t in [torch.tensor(self._text_to_indices(error)) for error in ast.literal_eval(utterance['grammar_errors'])]])\n",
        "                utterance['vocabulary_errors'] = torch.cat([t for t in [torch.tensor(self._text_to_indices(error)) for error in ast.literal_eval(utterance['vocabulary_errors'])]])\n",
        "                utterance['pronunciation_errors'] = torch.cat([t for t in [torch.tensor(self._text_to_indices(error)) for error in ast.literal_eval(utterance['pronunciation_errors'])]])\n",
        "                utterance['fluency_feedback'] = torch.tensor(self._text_to_indices(utterance['fluency_feedback']))\n",
        "                utterance['grammar_score'] = torch.tensor(utterance['grammar_score'])\n",
        "                utterance['vocabulary_score'] = torch.tensor(utterance['vocabulary_score'])\n",
        "                utterance['fluency_score'] = torch.tensor(utterance['fluency_score'])\n",
        "                utterance['pronunciation_score'] = torch.tensor(utterance['pronunciation_score'])\n",
        "            user_sequences[user_id] = {\n",
        "                'interactions': interaction_seq,\n",
        "                'utterances': utterance_seq\n",
        "            }\n",
        "        return user_sequences\n",
        "\n",
        "    def _text_to_indices(self, text):\n",
        "        return [self.vocab.get(word, self.vocab['<UNK>']) for word in re.findall(r'\\w+', text.lower())]\n",
        "\n",
        "    def _pad_sequence(self, sequence, max_length):\n",
        "        if len(sequence) < max_length:\n",
        "            padding = [\n",
        "                {k: torch.tensor([self.vocab['<PAD>']]) if isinstance(v, torch.Tensor) and v.dim() == 1\n",
        "                   else torch.tensor(0) if isinstance(v, torch.Tensor) and v.dim() == 0\n",
        "                   else '<PAD>' if isinstance(v, str)\n",
        "                   else 0 for k, v in sequence[0].items()}\n",
        "                for _ in range(max_length - len(sequence))\n",
        "            ]\n",
        "            return padding + sequence\n",
        "        return sequence[-max_length:]\n",
        "\n",
        "    def _sample_negative_exercises(self, user_id, positive_exercise_id, num_negatives=5):\n",
        "        user_exercises = set(self.user_interactions[self.user_interactions['user_id'] == user_id]['exercise_id'])\n",
        "        negative_exercises = self.exercises[~(self.exercises['exercise_id'].isin(user_exercises))].sample(num_negatives)\n",
        "\n",
        "        # Convert text fields in negative_exercises to indices\n",
        "        negative_exercises_list = []\n",
        "        for _, exercise in negative_exercises.iterrows():\n",
        "            exercise_dict = exercise.to_dict()\n",
        "            exercise_dict['type'] = torch.tensor(self._text_to_indices(exercise_dict['type']))\n",
        "            exercise_dict['category'] = torch.tensor(self._text_to_indices(exercise_dict['category']))\n",
        "            exercise_dict['content'] = torch.tensor(self._text_to_indices(exercise_dict['content']))\n",
        "            exercise_dict['metadata'] = torch.tensor(self._text_to_indices(str(ast.literal_eval(exercise_dict['metadata']))))\n",
        "            exercise_dict['difficulty'] = torch.tensor(exercise_dict['difficulty'])\n",
        "            negative_exercises_list.append(exercise_dict)\n",
        "\n",
        "        return negative_exercises_list\n",
        "    def __getitem__(self, idx):\n",
        "        user_id = self.user_profiles.iloc[idx]['user_id']\n",
        "        user_profile = self.user_profiles.iloc[idx].to_dict()\n",
        "\n",
        "        # Convert text fields in user_profile to tensor indices in proper shape\n",
        "        user_profile['location'] = torch.tensor(self._text_to_indices(user_profile['location']))\n",
        "        user_profile['native_language'] = torch.tensor(self._text_to_indices(user_profile['native_language']))\n",
        "        user_profile['proficiency_level'] = torch.tensor(self._text_to_indices(user_profile['proficiency_level']))\n",
        "        user_profile['interests'] = torch.cat([t for t in [torch.tensor(self._text_to_indices(interest)) for interest in ast.literal_eval(user_profile['interests'])]])\n",
        "        user_profile['preferred_learning_style'] = torch.tensor(self._text_to_indices(user_profile['preferred_learning_style']))\n",
        "        user_profile['age'] = torch.tensor(user_profile['age'])\n",
        "        # Prepare user sequences (one per user for simplicity)\n",
        "        user_seq = self.user_sequences[user_id]\n",
        "        interaction_seq = user_seq['interactions'][-self.seq_length:]\n",
        "        utterance_seq = user_seq['utterances'][-self.seq_length:]\n",
        "\n",
        "        # Pad sequences\n",
        "        interaction_seq = self._pad_sequence(interaction_seq, self.seq_length)\n",
        "        utterance_seq = self._pad_sequence(utterance_seq, self.seq_length)\n",
        "\n",
        "        # Sample a positive exercise (last interaction)\n",
        "        positive_exercise_id = interaction_seq[-1]['exercise_id']\n",
        "        positive_exercise = self.exercises[self.exercises['exercise_id'] == positive_exercise_id].iloc[0].to_dict()\n",
        "\n",
        "        # Convert text fields in positive_exercise to indices\n",
        "        positive_exercise['type'] = torch.tensor(self._text_to_indices(positive_exercise['type']))\n",
        "        positive_exercise['category'] = torch.tensor(self._text_to_indices(positive_exercise['category']))\n",
        "        positive_exercise['content'] = torch.tensor(self._text_to_indices(positive_exercise['content']))\n",
        "        positive_exercise['metadata'] = torch.tensor(self._text_to_indices(str(ast.literal_eval(positive_exercise['metadata']))))\n",
        "        positive_exercise['difficulty'] = torch.tensor(positive_exercise['difficulty'])\n",
        "        # Sample negative exercises\n",
        "        negative_exercises = self._sample_negative_exercises(user_id, positive_exercise_id)\n",
        "        return {\n",
        "            'user_profile': {key: value for key, value in user_profile.items() if key != 'user_id'},\n",
        "            'interaction_seq': [{key: value for key, value in interaction.items() if key != 'exercise_id'} for interaction in interaction_seq[:-1]],\n",
        "            'utterance_seq': utterance_seq,\n",
        "            'positive_exercise': {key: value for key, value in positive_exercise.items() if key != 'exercise_id'},\n",
        "            'negative_exercises': [{key: value for key, value in neg_exer.items() if key != 'exercise_id'} for neg_exer in negative_exercises]\n",
        "        }\n",
        "\n",
        "def pad_to_max_length(tensor_input, max_length=20):\n",
        "    # Check if the input is a nested list\n",
        "    if isinstance(tensor_input[0], list):\n",
        "        # Handle nested list structure\n",
        "        padded = []\n",
        "        for group in tensor_input:\n",
        "            padded_group = []\n",
        "            for tensor in group:\n",
        "                # Truncate if length is greater than max_length\n",
        "                if len(tensor) > max_length:\n",
        "                    truncated_tensor = tensor[:max_length]\n",
        "                else:\n",
        "                    truncated_tensor = tensor\n",
        "\n",
        "                # Pad to max_length if needed\n",
        "                padding = max_length - len(truncated_tensor)\n",
        "                padded_tensor = F.pad(truncated_tensor, (0, padding), value=0)  # Pad on the right\n",
        "                padded_group.append(padded_tensor)\n",
        "\n",
        "            # Stack the tensors in the group to form a tensor\n",
        "            padded.append(torch.stack(padded_group))\n",
        "    else:\n",
        "        # Handle flat list of tensors\n",
        "        padded = []\n",
        "        for tensor in tensor_input:\n",
        "            # Truncate if length is greater than max_length\n",
        "            if len(tensor) > max_length:\n",
        "                truncated_tensor = tensor[:max_length]\n",
        "            else:\n",
        "                truncated_tensor = tensor\n",
        "\n",
        "            # Pad to max_length if needed\n",
        "            padding = max_length - len(truncated_tensor)\n",
        "            padded_tensor = F.pad(truncated_tensor, (0, padding), value=0)  # Pad on the right\n",
        "            padded.append(padded_tensor)\n",
        "\n",
        "        # Stack to form a tensor\n",
        "        padded = torch.stack(padded)\n",
        "\n",
        "    return padded\n",
        "\n",
        "def collate_fn(batch):\n",
        "    BATCH_SIZE = len(batch)\n",
        "\n",
        "\n",
        "    age = torch.tensor([item['age'] for item in [items['user_profile'] for items in batch]]).reshape(BATCH_SIZE, 1)\n",
        "    locations = pad_to_max_length([item['location'] for item in [items['user_profile'] for items in batch]])\n",
        "    native_languages = pad_to_max_length([item['native_language'] for item in [items['user_profile'] for items in batch]])\n",
        "    proficiency_levels = pad_to_max_length([item['proficiency_level'] for item in [items['user_profile'] for items in batch]])\n",
        "    interests = pad_to_max_length([item['interests'] for item in [items['user_profile'] for items in batch]])\n",
        "    learning_styles = pad_to_max_length([item['preferred_learning_style'] for item in [items['user_profile'] for items in batch]])\n",
        "\n",
        "\n",
        "    interaction_performance = torch.tensor([[interaction['performance'] for interaction in user_interactions] for user_interactions in [items['interaction_seq'] for items in batch]])\n",
        "    interaction_time_spent = torch.tensor([[interaction['time_spent'] for interaction in user_interactions] for user_interactions in [items['interaction_seq'] for items in batch]])\n",
        "    interaction_user_response = [[interaction['user_response'] for interaction in user_interactions] for user_interactions in [items['interaction_seq'] for items in batch]]\n",
        "    interaction_user_feedback = [[interaction['user_feedback'] for interaction in user_interactions] for user_interactions in [items['interaction_seq'] for items in batch]]\n",
        "\n",
        "\n",
        "    utterances = [[interaction['utterance'] for interaction in user_interactions] for user_interactions in [items['utterance_seq'] for items in batch]]\n",
        "    grammar_score = torch.tensor([[interaction['grammar_score'] for interaction in user_interactions] for user_interactions in [items['utterance_seq'] for items in batch]])\n",
        "    fluency_score = torch.tensor([[interaction['fluency_score'] for interaction in user_interactions] for user_interactions in [items['utterance_seq'] for items in batch]])\n",
        "    pronunciation_score = torch.tensor([[interaction['pronunciation_score'] for interaction in user_interactions] for user_interactions in [items['utterance_seq'] for items in batch]])\n",
        "    vocabulary_score = torch.tensor([[interaction['vocabulary_score'] for interaction in user_interactions] for user_interactions in [items['utterance_seq'] for items in batch]])\n",
        "    grammar_errors = [[interaction['grammar_errors'] for interaction in user_interactions] for user_interactions in [items['utterance_seq'] for items in batch]]\n",
        "    vocabulary_errors = [[interaction['vocabulary_errors'] for interaction in user_interactions] for user_interactions in [items['utterance_seq'] for items in batch]]\n",
        "    pronunciation_errors = [[interaction['pronunciation_errors'] for interaction in user_interactions] for user_interactions in [items['utterance_seq'] for items in batch]]\n",
        "    fluency_feedback = [[interaction['fluency_feedback'] for interaction in user_interactions] for user_interactions in [items['utterance_seq'] for items in batch]]\n",
        "\n",
        "\n",
        "    positive_exercise_type = [item['type'] for item in [items['positive_exercise'] for items in batch]]\n",
        "    positive_exercise_category = [item['category'] for item in [items['positive_exercise'] for items in batch]]\n",
        "    positive_exercise_content = [item['content'] for item in [items['positive_exercise'] for items in batch]]\n",
        "    positive_exercise_metadata = [item['metadata'] for item in [items['positive_exercise'] for items in batch]]\n",
        "    positive_exercise_difficulty = torch.stack([pos_exer['difficulty'] for pos_exer in [item['positive_exercise'] for item in batch]])\n",
        "\n",
        "    negative_exercise_type = [[interaction['type'] for interaction in user_interactions] for user_interactions in [items['negative_exercises'] for items in batch]]\n",
        "    negative_exercise_category = [[interaction['category'] for interaction in user_interactions] for user_interactions in [items['negative_exercises'] for items in batch]]\n",
        "    negative_exercise_content = [[interaction['content'] for interaction in user_interactions] for user_interactions in [items['negative_exercises'] for items in batch]]\n",
        "    negative_exercise_metadata = [[interaction['metadata'] for interaction in user_interactions] for user_interactions in [items['negative_exercises'] for items in batch]]\n",
        "    negative_exercise_difficulty = [[neg_exer['difficulty'] for neg_exer in negative_exercises] for negative_exercises in [item['negative_exercises'] for item in batch]]\n",
        "\n",
        "    padded_interaction_user_response = pad_to_max_length(interaction_user_response)\n",
        "    padded_interaction_user_feedback = pad_to_max_length(interaction_user_feedback)\n",
        "    padded_utterances = pad_to_max_length(utterances)\n",
        "    padded_grammar_errors = pad_to_max_length(grammar_errors)\n",
        "    padded_vocabulary_errors = pad_to_max_length(vocabulary_errors)\n",
        "    padded_pronunciation_errors = pad_to_max_length(pronunciation_errors)\n",
        "    padded_fluency_feedback = pad_to_max_length(fluency_feedback)\n",
        "    padded_positive_exercise_type = pad_to_max_length(positive_exercise_type)\n",
        "    padded_positive_exercise_category = pad_to_max_length(positive_exercise_category)\n",
        "    padded_positive_exercise_content = pad_to_max_length(positive_exercise_content)\n",
        "    padded_positive_exercise_metadata = pad_to_max_length(positive_exercise_metadata)\n",
        "    padded_negative_exercise_type = pad_to_max_length(negative_exercise_type)\n",
        "    padded_negative_exercise_category = pad_to_max_length(negative_exercise_category)\n",
        "    padded_negative_exercise_content = pad_to_max_length(negative_exercise_content)\n",
        "    padded_negative_exercise_metadata = pad_to_max_length(negative_exercise_metadata)\n",
        "    # Create a dictionary to return everything\n",
        "    return {\n",
        "        'user_profile_data':{\n",
        "        'age': torch.stack([item for item in age]),\n",
        "        'location': torch.stack([item for item in locations]),\n",
        "        'native_language': torch.stack([item for item in native_languages]),\n",
        "        'proficiency_level': torch.stack([item for item in proficiency_levels]),\n",
        "        'interest': torch.stack([item for item in interests]),\n",
        "        'learning_style': torch.stack([item for item in learning_styles])\n",
        "        },\n",
        "        'interactions_data':{\n",
        "        'performance': torch.stack([item for item in interaction_performance]),\n",
        "        'time_spent': torch.stack([item for item in interaction_time_spent]),\n",
        "        'user_response': torch.stack([item for item in padded_interaction_user_response]),\n",
        "        'user_feedback': torch.stack([item for item in padded_interaction_user_feedback])\n",
        "        },\n",
        "        'utterances_data':{\n",
        "        'utterances': torch.stack([item for item in padded_utterances]),\n",
        "        'grammar_score': torch.stack([item for item in grammar_score]),\n",
        "        'fluency_score': torch.stack([item for item in fluency_score]),\n",
        "        'pronunciation_score': torch.stack([item for item in pronunciation_score]),\n",
        "        'vocabulary_score': torch.stack([item for item in vocabulary_score]),\n",
        "        'grammar_errors': torch.stack([item for item in padded_grammar_errors]),\n",
        "        'vocabulary_errors': torch.stack([item for item in padded_vocabulary_errors]),\n",
        "        'pronunciation_errors': torch.stack([item for item in padded_pronunciation_errors]),\n",
        "        'fluency_feedback': torch.stack([item for item in padded_fluency_feedback])\n",
        "        },\n",
        "        'positive_exercise_data':{\n",
        "        'exercise_type': torch.stack([item for item in padded_positive_exercise_type]),\n",
        "        'exercise_category': torch.stack([item for item in padded_positive_exercise_category]),\n",
        "        'exercise_content': torch.stack([item for item in padded_positive_exercise_content]),\n",
        "        'exercise_metadata': torch.stack([item for item in padded_positive_exercise_metadata]),\n",
        "        'exercise_difficulty': torch.stack([item for item in positive_exercise_difficulty])\n",
        "        },\n",
        "        'negative_exercise_data':{\n",
        "        'exercise_type': torch.stack([item for item in padded_negative_exercise_type]),\n",
        "        'exercise_category': torch.stack([item for item in padded_negative_exercise_category]),\n",
        "        'exercise_content': torch.stack([item for item in padded_negative_exercise_content]),\n",
        "        'exercise_metadata': torch.stack([item for item in padded_negative_exercise_metadata]),\n",
        "        'exercise_difficulty': torch.stack([torch.stack(x) for x in negative_exercise_difficulty])\n",
        "        }\n",
        "    }\n",
        "dataset = CandidateGenerationDataset(user_profiles_df, user_interactions_df, user_utterances_df, exercises_df, vocab)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn = collate_fn)"
      ],
      "metadata": {
        "id": "3zzkvW4Q_dXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class UserTower(nn.Module):\n",
        "    def __init__(self, profile_dim, hidden_dim, output_dim, embed_dim):\n",
        "        super(UserTower, self).__init__()\n",
        "        self.profile_encoder = nn.Linear(profile_dim, hidden_dim)\n",
        "        self.interaction_lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional = True)\n",
        "        self.utterance_lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True,bidirectional = True)\n",
        "        self.combiner = nn.Linear(hidden_dim * 5, output_dim)\n",
        "\n",
        "    def forward(self, profile, interaction_seq, utterance_seq):\n",
        "        profile_encoded = self.profile_encoder(profile)\n",
        "        _, (interaction_hidden, _) = self.interaction_lstm(interaction_seq)\n",
        "        _, (utterance_hidden, _) = self.utterance_lstm(utterance_seq)\n",
        "        combined = torch.cat([\n",
        "            profile_encoded,\n",
        "            interaction_hidden.squeeze(0).reshape(profile_encoded.shape[0],-1),\n",
        "            utterance_hidden.squeeze(0).reshape(profile_encoded.shape[0],-1)\n",
        "        ], dim=-1)\n",
        "        output = self.combiner(combined)\n",
        "        return output\n",
        "\n",
        "class ExerciseTower(nn.Module):\n",
        "    def __init__(self, exercise_dim, hidden_dim, output_dim):\n",
        "        super(ExerciseTower, self).__init__()\n",
        "        self.exercise_encoder = nn.Sequential(\n",
        "            nn.Linear(exercise_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, exercise):\n",
        "        return self.exercise_encoder(exercise)\n",
        "\n",
        "class CandidateGenerationModel(nn.Module):\n",
        "    def __init__(self, vocab_size, profile_dim, exercise_dim, hidden_dim, output_dim, embed_dim):\n",
        "        super(CandidateGenerationModel, self).__init__()\n",
        "        self.user_tower = UserTower(profile_dim, hidden_dim, output_dim, embed_dim)\n",
        "        self.exercise_tower = ExerciseTower(exercise_dim, hidden_dim, output_dim)\n",
        "\n",
        "        self.word_embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "    def forward(self, user_profile_data, interactions_data, utterances_data, positive_exercise_data, negative_exercises_data, embed_dim):\n",
        "        user_profile_emb = self.process_user_profiles(user_profile_data,embed_dim)\n",
        "        interactions_emb = self.process_user_interactions(interactions_data,embed_dim)\n",
        "        utterances_emb = self.process_utterances(utterances_data,embed_dim)\n",
        "        # print(user_profile_emb.shape)\n",
        "        # print(interactions_emb.shape)\n",
        "        # print(utterances_emb.shape)\n",
        "        user_ability_vector = self.user_tower(user_profile_emb, interactions_emb, utterances_emb)\n",
        "\n",
        "        positive_exercise_emb = self.process_exercises(positive_exercise_data, 'positive')\n",
        "        positive_exercise_embeddings = self.exercise_tower(positive_exercise_emb)\n",
        "\n",
        "        negative_exercise_emb = self.process_exercises(negative_exercises_data, 'negative')\n",
        "        neg_exercise_representation = []\n",
        "        for exercise in negative_exercise_emb:\n",
        "          neg_exercise_representation.append(self.exercise_tower(exercise))\n",
        "\n",
        "        positive_dot = torch.sum(user_ability_vector * positive_exercise_embeddings, dim=1)\n",
        "        dots = [torch.sum(user_ability_vector * exercise_representation,dim = 1) for exercise_representation in neg_exercise_representation]\n",
        "        dots.append(positive_dot)\n",
        "        return dots\n",
        "\n",
        "    def process_user_profiles(self, user_profile, embed_dim): # output shape : (batch, profile_dim)  profile_dim = 150*embed_dim+1\n",
        "        location_encoded = self.word_embedding(user_profile['location'])\n",
        "        language_encoded = self.word_embedding(user_profile['native_language'])\n",
        "        proficiency_encoded = self.word_embedding(user_profile['proficiency_level'])\n",
        "        interest_encoded = self.word_embedding(user_profile['interest'])\n",
        "        learning_style_encoded = self.word_embedding(user_profile['learning_style'])\n",
        "        age = (user_profile['age']-60)/40\n",
        "        profile_features = torch.cat((location_encoded,language_encoded,\n",
        "                                      proficiency_encoded,interest_encoded,learning_style_encoded), dim = 1).reshape(location_encoded.shape[0],-1)\n",
        "        profile_features = torch.cat((profile_features, age), dim=-1)\n",
        "\n",
        "        return profile_features\n",
        "\n",
        "    def process_user_interactions(self, interactions, embed_dim): # output_shape = (batch,seq_len,embed_dim)    seq_len vary from batch to batch.\n",
        "        user_responses = self.word_embedding(interactions['user_response'])\n",
        "        user_feedbacks = self.word_embedding(interactions['user_feedback'])\n",
        "        performances = interactions['performance']\n",
        "        time_spent = interactions['time_spent']\n",
        "\n",
        "        # user_responses = user_responses.reshape(user_responses.shape[0],-1,user_responses.shape[-1])\n",
        "        # user_feedbacks = user_feedbacks.reshape(user_feedbacks.shape[0],-1,user_feedbacks.shape[-1])\n",
        "\n",
        "        combined_interaction_features = torch.cat([user_responses, user_feedbacks], dim=2)\n",
        "        performances = performances.reshape(performances.shape[0],performances.shape[1],1,1).expand(performances.shape[0],performances.shape[1],1,embed_dim)\n",
        "        time_spent = time_spent.reshape(time_spent.shape[0],time_spent.shape[1],1,1).expand(time_spent.shape[0],time_spent.shape[1],1,embed_dim)\n",
        "        combined_interaction_features = torch.cat((combined_interaction_features,performances, time_spent), dim = 2)\n",
        "        combined_interaction_features = combined_interaction_features.reshape(combined_interaction_features.shape[0],-1,combined_interaction_features.shape[-1])\n",
        "\n",
        "        return combined_interaction_features\n",
        "\n",
        "    def process_utterances(self, utterances, embed_dim): #output_shape = (batch,seq_len,embed_dim) seq_len vary from batch to batch.\n",
        "        utterance_emb = self.word_embedding(utterances['utterances'])\n",
        "        grammar_error_emb = self.word_embedding(utterances['grammar_errors'])\n",
        "        vocabulary_error_emb = self.word_embedding(utterances['vocabulary_errors'])\n",
        "        pronunciation_error_emb = self.word_embedding(utterances['pronunciation_errors'])\n",
        "        fluency_feedback_emb = self.word_embedding(utterances['fluency_feedback'])\n",
        "\n",
        "        grammar_score = utterances['grammar_score']\n",
        "        vocabulary_score = utterances['vocabulary_score']\n",
        "        pronunciation_score = utterances['pronunciation_score']\n",
        "        fluency_score = utterances['fluency_score']\n",
        "\n",
        "        combined_utterance_features = torch.cat((utterance_emb, grammar_error_emb,\n",
        "                                                 vocabulary_error_emb,pronunciation_error_emb, fluency_feedback_emb), dim = 2)\n",
        "\n",
        "        grammar_score = grammar_score.reshape(utterance_emb.shape[0],utterance_emb.shape[1],1,1).expand(utterance_emb.shape[0],utterance_emb.shape[1],1,embed_dim)\n",
        "        vocabulary_score = vocabulary_score.reshape(utterance_emb.shape[0],utterance_emb.shape[1],1,1).expand(utterance_emb.shape[0],utterance_emb.shape[1],1,embed_dim)\n",
        "        pronunciation_score = pronunciation_score.reshape(utterance_emb.shape[0],utterance_emb.shape[1],1,1).expand(utterance_emb.shape[0],utterance_emb.shape[1],1,embed_dim)\n",
        "        fluency_score = fluency_score.reshape(utterance_emb.shape[0],utterance_emb.shape[1],1,1).expand(utterance_emb.shape[0],utterance_emb.shape[1],1,embed_dim)\n",
        "        combined_utterance_features = torch.cat((combined_utterance_features, grammar_score, vocabulary_score, pronunciation_score,fluency_score), dim = 2)\n",
        "\n",
        "        combined_utterance_features = combined_utterance_features.reshape(combined_utterance_features.shape[0],-1,combined_utterance_features.shape[-1])\n",
        "\n",
        "        return combined_utterance_features\n",
        "\n",
        "    def process_exercises(self, exercises, _type): # Output shape: For positive_exer: (batch, 120*embed_dim+1)\n",
        "                                                        # Negative_exer: (num_neg_exercise, batch, 120*embed_dim+1)\n",
        "        if _type=='positive':\n",
        "            content_emb = self.word_embedding(exercises['exercise_content'])\n",
        "            metadata_emb = self.word_embedding(exercises['exercise_metadata'])\n",
        "            type_encoded = self.word_embedding(exercises['exercise_type'])\n",
        "            category_encoded = self.word_embedding(exercises['exercise_category'])\n",
        "            difficulty = exercises['exercise_difficulty'].unsqueeze(1)\n",
        "\n",
        "            exercise_features = torch.cat((content_emb,metadata_emb,type_encoded,category_encoded), dim = 1)\n",
        "            exercise_features = torch.cat((exercise_features.reshape(exercise_features.shape[0],-1),difficulty), dim=-1)\n",
        "        else:\n",
        "            content_emb = self.word_embedding(exercises['exercise_content'])\n",
        "            metadata_emb = self.word_embedding(exercises['exercise_metadata'])\n",
        "            type_encoded = self.word_embedding(exercises['exercise_type'])\n",
        "            category_encoded = self.word_embedding(exercises['exercise_category'])\n",
        "            difficulty = exercises['exercise_difficulty'].unsqueeze(2)\n",
        "            content_emb = content_emb.reshape(content_emb.shape[0],content_emb.shape[1],-1)\n",
        "            metadata_emb = metadata_emb.reshape(metadata_emb.shape[0],metadata_emb.shape[1],-1)\n",
        "            type_encoded = type_encoded.reshape(type_encoded.shape[0],type_encoded.shape[1],-1)\n",
        "            category_encoded = category_encoded.reshape(category_encoded.shape[0],category_encoded.shape[1],-1)\n",
        "\n",
        "            exercise_features = torch.cat([content_emb, metadata_emb, type_encoded, category_encoded], dim=-1)\n",
        "            exercise_features = torch.cat((exercise_features, difficulty), dim=-1).reshape(exercise_features.shape[1],exercise_features.shape[0],-1)\n",
        "\n",
        "        return exercise_features"
      ],
      "metadata": {
        "id": "__O3Ogh6XGUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "metadata": {
        "id": "6wo7tJ6JeFtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_candidate_generation_model(model, train_dataloader, num_epochs, learning_rate, device, embed_dim):\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        # Training loop with progress bar\n",
        "        train_bar = tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
        "        for batch in train_bar:\n",
        "            # Move batch data to device\n",
        "            user_profile_data = {k: v.to(device) for k, v in batch['user_profile_data'].items()}\n",
        "            interactions_data = {k: v.to(device) for k, v in batch['interactions_data'].items()}\n",
        "            utterances_data = {k: v.to(device) for k, v in batch['utterances_data'].items()}\n",
        "            positive_exercise_data = {k: v.to(device) for k, v in batch['positive_exercise_data'].items()}\n",
        "            negative_exercise_data = {k: v.to(device) for k, v in batch['negative_exercise_data'].items()}\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass\n",
        "            dots = model(user_profile_data, interactions_data, utterances_data, positive_exercise_data, negative_exercise_data, embed_dim)\n",
        "\n",
        "            # Adjust labels based on the position of the positive exercise\n",
        "            # positive exercise is at the end of the `dots` list, assign 1 to the last index.\n",
        "            labels = torch.zeros(dots[0].shape[0], dtype=torch.long).to(device)  # Initialize all to 0\n",
        "            labels[-1] = 1\n",
        "\n",
        "            loss = criterion(torch.stack(dots, dim=1), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            print(loss.item())\n",
        "            total_loss += loss.item()\n",
        "            train_bar.set_postfix({'loss': loss.item()})\n",
        "        #     break\n",
        "        # break\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}')"
      ],
      "metadata": {
        "id": "wr5X9GzQ_zZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 64\n",
        "profile_dim = 100*embed_dim+1\n",
        "exercise_dim = 80*embed_dim+1\n",
        "\n",
        "model = CandidateGenerationModel(vocab_size, profile_dim = profile_dim, exercise_dim = exercise_dim, hidden_dim = 64, output_dim = 8, embed_dim=embed_dim)\n",
        "num_epochs = 10\n",
        "learning_rate = 0.0001\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_candidate_generation_model(model, dataloader, num_epochs, learning_rate, device, embed_dim)"
      ],
      "metadata": {
        "id": "YRsipQ5QBgOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971cf034-14be-46e4-bd9a-7bcd3516ef42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Train]: 100%|| 1/1 [00:01<00:00,  1.59s/it, loss=1.79]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7925946712493896\n",
            "Epoch 1/10 - Train Loss: 1.7926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10 [Train]: 100%|| 1/1 [00:01<00:00,  1.18s/it, loss=1.76]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7638753652572632\n",
            "Epoch 2/10 - Train Loss: 1.7639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10 [Train]: 100%|| 1/1 [00:00<00:00,  1.05it/s, loss=1.77]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.76968514919281\n",
            "Epoch 3/10 - Train Loss: 1.7697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10 [Train]: 100%|| 1/1 [00:00<00:00,  1.03it/s, loss=1.93]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9296705722808838\n",
            "Epoch 4/10 - Train Loss: 1.9297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10 [Train]: 100%|| 1/1 [00:00<00:00,  1.02it/s, loss=1.83]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.8286470174789429\n",
            "Epoch 5/10 - Train Loss: 1.8286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10 [Train]: 100%|| 1/1 [00:01<00:00,  1.31s/it, loss=1.81]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.8149144649505615\n",
            "Epoch 6/10 - Train Loss: 1.8149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10 [Train]: 100%|| 1/1 [00:00<00:00,  1.04it/s, loss=1.91]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9148266315460205\n",
            "Epoch 7/10 - Train Loss: 1.9148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10 [Train]: 100%|| 1/1 [00:00<00:00,  1.02it/s, loss=1.77]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7663570642471313\n",
            "Epoch 8/10 - Train Loss: 1.7664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10 [Train]: 100%|| 1/1 [00:00<00:00,  1.04it/s, loss=1.79]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.787714958190918\n",
            "Epoch 9/10 - Train Loss: 1.7877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10 [Train]: 100%|| 1/1 [00:00<00:00,  1.01it/s, loss=1.75]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7496503591537476\n",
            "Epoch 10/10 - Train Loss: 1.7497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Candidate Generation Inference"
      ],
      "metadata": {
        "id": "Dy5NdM6F-SkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "-> Create function for getting last L sequences of User Utterance, L1 sequences of user_exercise_interaction ->\n",
        "-> Create function for preprocessing ->\n",
        "-> Prepare the data for the model ->\n",
        "-> Forward pass\n",
        "-> Get candidates based on N nearest neighbour"
      ],
      "metadata": {
        "id": "oZsAYsRF-V8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Initialize the model and set it to evaluation mode\n",
        "model = CandidateGenerationModel(vocab_size, profile_dim = profile_dim, exercise_dim = exercise_dim, hidden_dim = 64, output_dim = 8, embed_dim=embed_dim)\n",
        "model.eval()\n",
        "\n",
        "# We get this from real data\n",
        "user_profile = torch.randn((1, profile_dim))  # Single user profile\n",
        "interaction_seq = torch.randn((1, 10, interaction_dim))  # Interaction sequence (10 steps)\n",
        "utterance_seq = torch.randn((1, 10, utterance_dim))  # Utterance sequence (10 steps)\n",
        "\n",
        "# Disable gradient computation for inference\n",
        "with torch.no_grad():\n",
        "    # Step 1: Getting user embedding from the user tower\n",
        "    user_embedding = model.user_tower(user_profile, interaction_seq, utterance_seq)\n",
        "\n",
        "# Assuming we have precomputed exercise embeddings for all exercises in the repository\n",
        "# (This can be done offline during training or periodically updated in a nearest-neighbor index)\n",
        "exercise_embeddings = np.load('exercise_embeddings.npy')  # Precomputed embeddings\n",
        "\n",
        "# Step 2: Initialize a nearest neighbor search model\n",
        "n_neighbors = 10  # Number of candidate exercises to return\n",
        "nearest_neighbors_model = NearestNeighbors(n_neighbors=n_neighbors, algorithm='ball_tree')\n",
        "nearest_neighbors_model.fit(exercise_embeddings)\n",
        "\n",
        "# Step 3: Finding the N nearest exercises for the user\n",
        "user_embedding = user_embedding.numpy()  # Convert to numpy for NearestNeighbors\n",
        "distances, indices = nearest_neighbors_model.kneighbors(user_embedding)\n",
        "\n",
        "# Step 4: Retrieve the N closest exercises\n",
        "candidate_exercises = [exercise_embeddings[idx] for idx in indices[0]]\n",
        "\n",
        "# Output candidate exercise IDs (or embeddings)\n",
        "print(\"Top N candidate exercises for the user:\", indices[0])"
      ],
      "metadata": {
        "id": "kodnMyPP-V6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing dataset for pre training of Candidate Ranking Model"
      ],
      "metadata": {
        "id": "FSpTWuzY6bpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "-> generate (u,i,j) triplets\n",
        "  -> need user_embedding(user_ability_vector) at the time of just before each interaction, for each user.\n",
        "    -> need a function for generating user_embeddings given a user and a timestamp (easy)\n",
        "      -> Get user static features from profile, user's 'past L utterances from the given timestamp, user's' past L exercise interactions from\n",
        "          the given timestamp, preprocess them, get feature vectors and then finally get user_embedding\n",
        "-> train with BPR loss"
      ],
      "metadata": {
        "id": "SBvgJl2lBaOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XAZkt1H5b9IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ON8eHiWcb94D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NR3EXgmKb91B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s1yyefn4b9y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jrn5GBgfb9v3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i8BWJgHSb9sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rWieURlDb9qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vfWGJPsXb9GV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rRFR7swtb9EZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MHqJ2ZEpb9B1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ipvdBvvBb8_n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}